{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b35538cb-97e2-4ebd-a2d3-18e271d075f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "from transformations.transform import WaveformToInput as TorchTransform\n",
    "from architecture.backend.yamnet.params import YAMNetParams\n",
    "from architecture.backend.yamnet.model import yamnet\n",
    "from architecture.backend.yamnet.model import yamnet_category_metadata\n",
    "\n",
    "from architecture.classifier.classification import Classifier\n",
    "\n",
    "from datasets.SvdExDataset import SvdCutOffShort\n",
    "from tqdm import tqdm\n",
    "import IPython\n",
    "\n",
    "from datasets.SvdExDataset import SvdExtendedVoiceDataset\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4d7f592-8fa1-402c-89be-fade65422ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3prl.hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c00a9f0-29df-45f4-848d-00dc9e9b65e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "{'data': tensor([[[12.3761, 11.7492, 11.3360,  ...,  7.6452,  7.6120,  7.9758],\n",
      "         [12.2741, 11.4850, 11.3448,  ...,  6.8388,  6.5159,  6.7437],\n",
      "         [12.2936, 11.7842,  9.7161,  ...,  6.7731,  5.9573,  6.6129],\n",
      "         ...,\n",
      "         [12.4582, 12.3116, 11.1653,  ...,  6.7223,  7.0045,  7.2922],\n",
      "         [12.2054, 11.9077, 11.1359,  ...,  6.9165,  7.2385,  7.2134],\n",
      "         [12.3611, 12.1957, 11.9286,  ...,  6.7778,  6.3635,  6.1738]]]), 'sampling_rate': 50000, 'classification': True}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f12e4-7466-4315-9223-c4d6ce76098a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dc428c9-a8bd-4a4b-a359-2ca710464420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tera = s3prl.hub.tera().to(device=\"cuda:0\")\n",
    "wav2vec2 = s3prl.hub.wav2vec2(refresh=True).to(device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "068c9a8e-70b2-40cb-878a-84c350817116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UpstreamExpert] - Using the default upstream expert config\n",
      "[DistillerModel] - Expands the output dimension by 3 times\n",
      "[DistillerModel] - Pred layers: [4, 8, 12]\n",
      "[TransformerEncoder] - Attention type = original\n",
      "[DistillerModel] - Out layer type: expand-last\n",
      "[DistillerModel] - Inter dim = 768\n"
     ]
    }
   ],
   "source": [
    "distilhubert = s3prl.hub.distilhubert(refresh=True).to(device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38c7bdb6-bc5d-4afd-b8ae-ac399e15c8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23234/23234 [01:52<00:00, 207.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 438, 768])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = {}\n",
    "hp[\"augmentations\"]=[]\n",
    "dataset = SvdExtendedVoiceDataset(r\"/home/yiftach.ede@staff.technion.ac.il/data/SVD/\",hp=hp,classification_binary=True)\n",
    "\n",
    "for data in tqdm(dataset):\n",
    "    data[\"data\"]=data[\"data\"].to(device=\"cuda:0\")\n",
    "    out=tera(data[\"data\"])\n",
    "    # break\n",
    "\n",
    "\n",
    "out['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea3ada1f-3aac-466e-b7bf-a0e025551e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23234 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['_hidden_states_info', 'hidden_states', 'last_hidden_state', 'hidden_state_0', 'hidden_state_1', 'hidden_state_2', 'hidden_state_3', 'hidden_state_4', 'hidden_state_5', 'hidden_state_6', 'hidden_state_7', 'hidden_state_8', 'hidden_state_9', 'hidden_state_10', 'hidden_state_11'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = {}\n",
    "hp[\"augmentations\"]=[]\n",
    "dataset = SvdExtendedVoiceDataset(r\"/home/yiftach.ede@staff.technion.ac.il/data/SVD/\",hp=hp,classification_binary=True)\n",
    "\n",
    "for data in tqdm(dataset):\n",
    "    data[\"data\"]=data[\"data\"].to(device=\"cuda:0\")\n",
    "    out=wav2vec2(data[\"data\"])\n",
    "    break\n",
    "\n",
    "\n",
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b48c6c8b-5f73-4e38-94f6-3db148ad7e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23234 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['last_hidden_state', 'hidden_states', 'pad_mask', 'paper'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = {}\n",
    "hp[\"augmentations\"]=[]\n",
    "dataset = SvdExtendedVoiceDataset(r\"/home/yiftach.ede@staff.technion.ac.il/data/SVD/\",hp=hp,classification_binary=True)\n",
    "\n",
    "for data in tqdm(dataset):\n",
    "    data[\"data\"]=data[\"data\"].to(device=\"cuda:0\")\n",
    "    out=distilhubert(data[\"data\"])\n",
    "    break\n",
    "\n",
    "\n",
    "out.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
