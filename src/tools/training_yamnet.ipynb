{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "from transformations.transform import WaveformToInput as TorchTransform\n",
    "from architecture.backend.yamnet.params import YAMNetParams\n",
    "from architecture.backend.yamnet.model import yamnet\n",
    "from architecture.backend.yamnet.model import yamnet_category_metadata\n",
    "\n",
    "from architecture.classifier.classification import Classifier\n",
    "\n",
    "from datasets.SvdExDataset import SvdCutOffShort\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Directory should not be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/chenka@staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000002vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000002vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000002vscode-remote?line=4'>5</a>\u001b[0m dataset \u001b[39m=\u001b[39m SvdCutOffShort(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/Users/yiftachedelstain/Development/VoiceDisorderIdentification/data\u001b[39;49m\u001b[39m\"\u001b[39;49m,classification_binary\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000002vscode-remote?line=5'>6</a>\u001b[0m loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000002vscode-remote?line=6'>7</a>\u001b[0m     dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000002vscode-remote?line=7'>8</a>\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000002vscode-remote?line=8'>9</a>\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000002vscode-remote?line=9'>10</a>\u001b[0m     num_workers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000002vscode-remote?line=10'>11</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000002vscode-remote?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_val_test_split\u001b[39m(ds):\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/datasets/SvdExDataset.py:48\u001b[0m, in \u001b[0;36mSvdCutOffShort.__init__\u001b[0;34m(self, root_dir, data_transform, label_transform, class_definitions, classification_binary, overfit_test)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root_dir, data_transform\u001b[39m=\u001b[39mdefault_transforms,label_transform\u001b[39m=\u001b[39mdefault_label_transforms, class_definitions\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,classification_binary\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,overfit_test \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=47'>48</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root_dir,data_transform,label_transform,class_definitions,classification_binary)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=48'>49</a>\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=49'>50</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles \u001b[39m=\u001b[39m [file \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles \u001b[39mif\u001b[39;00m librosa\u001b[39m.\u001b[39mget_duration(filename\u001b[39m=\u001b[39mfile)\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mcfg\u001b[39m.\u001b[39mVOICE_SAMPLE_MIN_LENGTH]\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/datasets/SvdExDataset.py:26\u001b[0m, in \u001b[0;36mSvdExtendedVoiceDataset.__init__\u001b[0;34m(self, root_dir, data_transform, label_transform, class_definitions, classification_binary)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=23'>24</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root,f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m files \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m f\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m  f\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=24'>25</a>\u001b[0m     \u001b[39m# assert len(files) == 0 or (len(files) != 0 and \u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=25'>26</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mDirectory should not be empty\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Directory should not be empty"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "dataset = SvdCutOffShort(r\"/Users/yiftachedelstain/Development/VoiceDisorderIdentification/data\",classification_binary=True)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "def train_val_test_split(ds):\n",
    "        ds_len =  len(ds)\n",
    "        len_test = math.floor(ds_len*0.2)\n",
    "        len_train_vald = ds_len - len_test\n",
    "        len_train = math.ceil(len_train_vald*0.8)\n",
    "        len_vald = len_train_vald - len_train\n",
    "        return torch.utils.data.random_split(ds, [len_train,len_vald,len_test]) \n",
    "\n",
    "train,val,test = train_val_test_split(dataset)\n",
    "# print(len(train),len(val),len(test),len(dataset))\n",
    "pt_model = Classifier([512,64])\n",
    "# print(pt_model)\n",
    "pt_model.eval()\n",
    "print(len(dataset))\n",
    "with torch.no_grad():\n",
    "\n",
    "# print(pt_model)\n",
    "    for epoch in range(2):\n",
    "        with tqdm(loader) as t:\n",
    "            for idx,x in enumerate(t):\n",
    "                # x = torch.from_numpy(patches)\n",
    "                # x = x.unsqueeze(1)  # [5, 96, 64] -> [5, 1, 96, 64]\n",
    "                t.set_description(f\"epoch {epoch}: train loss is {idx}\")\n",
    "                pt_pred = pt_model(x['data'])\n",
    "                # print(pt_pred['classification'])\n",
    "                # print(x['classification'])\n",
    "                # assert(x['classification'].all())\n",
    "                # print(pt_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/76 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/chenka@staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000003vscode-remote?line=7'>8</a>\u001b[0m hyper_params \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000003vscode-remote?line=8'>9</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain_batch_size\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m128\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000003vscode-remote?line=9'>10</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mvald_batch_size\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m128\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000003vscode-remote?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m10\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000003vscode-remote?line=13'>14</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000003vscode-remote?line=14'>15</a>\u001b[0m trainer \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mtrain_svd\u001b[39m.\u001b[39mTrainer(dataset\u001b[39m=\u001b[39mdataset,model\u001b[39m=\u001b[39mmodel,optimizers\u001b[39m=\u001b[39mopt,critereon\u001b[39m=\u001b[39mloss,hyper_params\u001b[39m=\u001b[39mhyper_params)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000003vscode-remote?line=15'>16</a>\u001b[0m model \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000003vscode-remote?line=16'>17</a>\u001b[0m trainer\u001b[39m.\u001b[39mtest(model[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/trainer/train_svd.py:64\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/trainer/train_svd.py?line=61'>62</a>\u001b[0m y \u001b[39m=\u001b[39m sample[\u001b[39m'\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/trainer/train_svd.py?line=62'>63</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/trainer/train_svd.py?line=63'>64</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/trainer/train_svd.py?line=64'>65</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritereon(outputs,y)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/trainer/train_svd.py?line=65'>66</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/architecture/classifier/classification.py:22\u001b[0m, in \u001b[0;36mClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/classifier/classification.py?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/classifier/classification.py?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassification(x)\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py:157\u001b[0m, in \u001b[0;36mYAMNet.forward\u001b[0;34m(self, x, to_prob)\u001b[0m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=154'>155</a>\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_names:\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=155'>156</a>\u001b[0m     mod \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[0;32m--> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=156'>157</a>\u001b[0m     x \u001b[39m=\u001b[39m mod(x)\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=157'>158</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39madaptive_avg_pool2d(x, \u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=158'>159</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py:90\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=88'>89</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=89'>90</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfused(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py:72\u001b[0m, in \u001b[0;36mCONV_BN_RELU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=70'>71</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=71'>72</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=72'>73</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn(x)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=73'>74</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py:55\u001b[0m, in \u001b[0;36mConv2d_tf.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=51'>52</a>\u001b[0m odd_2, padding_2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_SAME_padding(\u001b[39minput\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=52'>53</a>\u001b[0m \u001b[39mif\u001b[39;00m odd_1 \u001b[39mor\u001b[39;00m odd_2:\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=53'>54</a>\u001b[0m     \u001b[39m# NOTE: F.pad argument goes from last to first dim\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=54'>55</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mpad(\u001b[39minput\u001b[39;49m, [\u001b[39m0\u001b[39;49m, odd_2, \u001b[39m0\u001b[39;49m, odd_1])\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=56'>57</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_func(\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=57'>58</a>\u001b[0m     \u001b[39minput\u001b[39m, padding\u001b[39m=\u001b[39m[ padding_1 \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m, padding_2 \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m ]\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=58'>59</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/functional.py:4364\u001b[0m, in \u001b[0;36m_pad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/functional.py?line=4361'>4362</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(pad) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), \u001b[39m\"\u001b[39m\u001b[39mPadding length too large\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/functional.py?line=4362'>4363</a>\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/functional.py?line=4363'>4364</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mconstant_pad_nd(\u001b[39minput\u001b[39;49m, pad, value)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/functional.py?line=4364'>4365</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/functional.py?line=4365'>4366</a>\u001b[0m     \u001b[39massert\u001b[39;00m value \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPadding mode \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m doesn\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt take in value argument\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(mode)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import trainer.train_svd \n",
    "import torch.nn as nn\n",
    "import torch.optim \n",
    "dataset = SvdCutOffShort(r\"/home/chenka@staff.technion.ac.il/Desktop/SVD\",classification_binary=True,overfit_test = False)\n",
    "model = Classifier([512,128])\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "hyper_params = {\n",
    "    'train_batch_size':128,\n",
    "    'vald_batch_size':128,\n",
    "    'test_batch_size':128,\n",
    "    'num_workers':5,\n",
    "    'epochs':10\n",
    "}\n",
    "trainer = trainer.train_svd.Trainer(dataset=dataset,model=model,optimizers=opt,critereon=loss,hyper_params=hyper_params)\n",
    "model = trainer.train()\n",
    "trainer.test(model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/76 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/chenka@staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000004vscode-remote?line=21'>22</a>\u001b[0m hyper_params \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000004vscode-remote?line=22'>23</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain_batch_size\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m128\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000004vscode-remote?line=23'>24</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mvald_batch_size\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m128\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000004vscode-remote?line=26'>27</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m6\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000004vscode-remote?line=27'>28</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000004vscode-remote?line=28'>29</a>\u001b[0m trainer \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mtrain_svd\u001b[39m.\u001b[39mTrainer(dataset\u001b[39m=\u001b[39mdataset,model\u001b[39m=\u001b[39mmodel,optimizers\u001b[39m=\u001b[39mopt,critereon\u001b[39m=\u001b[39mloss,hyper_params\u001b[39m=\u001b[39mhyper_params)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000004vscode-remote?line=29'>30</a>\u001b[0m model \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000004vscode-remote?line=30'>31</a>\u001b[0m trainer\u001b[39m.\u001b[39mtest(model)\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/trainer/train_svd.py:64\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/trainer/train_svd.py?line=61'>62</a>\u001b[0m y \u001b[39m=\u001b[39m sample[\u001b[39m'\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/trainer/train_svd.py?line=62'>63</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/trainer/train_svd.py?line=63'>64</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/trainer/train_svd.py?line=64'>65</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritereon(outputs,y)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/trainer/train_svd.py?line=65'>66</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/architecture/classifier/classification.py:22\u001b[0m, in \u001b[0;36mClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/classifier/classification.py?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/classifier/classification.py?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassification(x)\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py:157\u001b[0m, in \u001b[0;36mYAMNet.forward\u001b[0;34m(self, x, to_prob)\u001b[0m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=154'>155</a>\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_names:\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=155'>156</a>\u001b[0m     mod \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[0;32m--> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=156'>157</a>\u001b[0m     x \u001b[39m=\u001b[39m mod(x)\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=157'>158</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39madaptive_avg_pool2d(x, \u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=158'>159</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py:90\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=88'>89</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=89'>90</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfused(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py:72\u001b[0m, in \u001b[0;36mCONV_BN_RELU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=70'>71</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=71'>72</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=72'>73</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn(x)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=73'>74</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py:55\u001b[0m, in \u001b[0;36mConv2d_tf.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=51'>52</a>\u001b[0m odd_2, padding_2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_SAME_padding(\u001b[39minput\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=52'>53</a>\u001b[0m \u001b[39mif\u001b[39;00m odd_1 \u001b[39mor\u001b[39;00m odd_2:\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=53'>54</a>\u001b[0m     \u001b[39m# NOTE: F.pad argument goes from last to first dim\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=54'>55</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mpad(\u001b[39minput\u001b[39;49m, [\u001b[39m0\u001b[39;49m, odd_2, \u001b[39m0\u001b[39;49m, odd_1])\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=56'>57</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_func(\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=57'>58</a>\u001b[0m     \u001b[39minput\u001b[39m, padding\u001b[39m=\u001b[39m[ padding_1 \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m, padding_2 \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m ]\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/architecture/backend/yamnet/model.py?line=58'>59</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/functional.py:4364\u001b[0m, in \u001b[0;36m_pad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/functional.py?line=4361'>4362</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(pad) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), \u001b[39m\"\u001b[39m\u001b[39mPadding length too large\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/functional.py?line=4362'>4363</a>\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/functional.py?line=4363'>4364</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mconstant_pad_nd(\u001b[39minput\u001b[39;49m, pad, value)\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/functional.py?line=4364'>4365</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/torch/nn/functional.py?line=4365'>4366</a>\u001b[0m     \u001b[39massert\u001b[39;00m value \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPadding mode \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m doesn\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt take in value argument\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(mode)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "from transformations.transform import WaveformToInput as TorchTransform\n",
    "from architecture.backend.yamnet.params import YAMNetParams\n",
    "from architecture.backend.yamnet.model import yamnet\n",
    "from architecture.backend.yamnet.model import yamnet_category_metadata\n",
    "\n",
    "from architecture.classifier.classification import Classifier\n",
    "\n",
    "from datasets.SvdExDataset import SvdCutOffShort\n",
    "import trainer.train_svd \n",
    "import torch.nn as nn\n",
    "import torch.optim \n",
    "\n",
    "dataset = SvdCutOffShort(r\"/home/chenka@staff.technion.ac.il/Desktop/SVD\",classification_binary=True,overfit_test = False)\n",
    "model = Classifier([512])\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "hyper_params = {\n",
    "    'train_batch_size':128,\n",
    "    'vald_batch_size':128,\n",
    "    'test_batch_size':128,\n",
    "    'num_workers':2,\n",
    "    'epochs':6\n",
    "}\n",
    "trainer = trainer.train_svd.Trainer(dataset=dataset,model=model,optimizers=opt,critereon=loss,hyper_params=hyper_params)\n",
    "model = trainer.train()\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformations.transform import WaveformToInput as TorchTransform\n",
    "from architecture.backend.yamnet.params import YAMNetParams\n",
    "from architecture.backend.yamnet.model import yamnet\n",
    "from architecture.backend.yamnet.model import yamnet_category_metadata\n",
    "\n",
    "from architecture.classifier.classification import Classifier\n",
    "\n",
    "from datasets.SvdExDataset import SvdCutOffShort\n",
    "import trainer.train_svd \n",
    "import torch.nn as nn\n",
    "import torch.optim \n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "model = Classifier([512, 256])\n",
    "\n",
    "\n",
    "dataset = SvdCutOffShort('/home/chenka@staff.technion.ac.il/Desktop/SVD',classification_binary=True,overfit_test = False)\n",
    "dataloader = DataLoader(dataset,          \n",
    "            shuffle=True            \n",
    "        )\n",
    "\n",
    "a = dataloader.dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30169/4255968014.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  b = np.array([[x['data'].tolist(),x['classification']] for x in a])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "b = np.array([[x['data'].tolist(),x['classification']] for x in a])\n",
    "\n",
    "X = torch.tensor(b[:,0].tolist())\n",
    "y = torch.tensor(b[:,1].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 15 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n15 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/classifier.py\", line 141, in fit\n    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/net.py\", line 1215, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/net.py\", line 1174, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/net.py\", line 1093, in fit_loop\n    self.notify(\"on_epoch_end\", **on_epoch_kwargs)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/net.py\", line 359, in notify\n    getattr(cb, method_name)(self, **cb_kwargs)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/callbacks/scoring.py\", line 472, in on_epoch_end\n    current_score = self._scoring(cached_net, X_test, y_test)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/callbacks/scoring.py\", line 180, in _scoring\n    return scorer(net, X_test, y_test)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 261, in _score\n    y_pred = method_caller(estimator, \"predict\", X)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 71, in _cached_call\n    return getattr(estimator, method)(*args, **kwargs)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/classifier.py\", line 208, in predict\n    return self.predict_proba(X).argmax(axis=1)\nnumpy.AxisError: axis 1 is out of bounds for array of dimension 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/chenka@staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000007vscode-remote?line=9'>10</a>\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39moptimizer__lr\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m1\u001b[39m,\u001b[39m0.1\u001b[39m,\u001b[39m0.01\u001b[39m]}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000007vscode-remote?line=11'>12</a>\u001b[0m cv \u001b[39m=\u001b[39m GridSearchCV(estimator,params,verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000007vscode-remote?line=12'>13</a>\u001b[0m cv\u001b[39m.\u001b[39;49mfit(X,y)\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=868'>869</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=869'>870</a>\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=870'>871</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=872'>873</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=874'>875</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=876'>877</a>\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=877'>878</a>\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=878'>879</a>\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=1372'>1373</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=1373'>1374</a>\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=1374'>1375</a>\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=844'>845</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=845'>846</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=846'>847</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=847'>848</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=848'>849</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=849'>850</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=851'>852</a>\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=853'>854</a>\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=854'>855</a>\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=855'>856</a>\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=856'>857</a>\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=857'>858</a>\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=359'>360</a>\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=360'>361</a>\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=361'>362</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=362'>363</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=363'>364</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=364'>365</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=365'>366</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=366'>367</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=368'>369</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=369'>370</a>\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=370'>371</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=371'>372</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=375'>376</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/chenka%40staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=376'>377</a>\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 15 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n15 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/classifier.py\", line 141, in fit\n    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/net.py\", line 1215, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/net.py\", line 1174, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/net.py\", line 1093, in fit_loop\n    self.notify(\"on_epoch_end\", **on_epoch_kwargs)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/net.py\", line 359, in notify\n    getattr(cb, method_name)(self, **cb_kwargs)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/callbacks/scoring.py\", line 472, in on_epoch_end\n    current_score = self._scoring(cached_net, X_test, y_test)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/callbacks/scoring.py\", line 180, in _scoring\n    return scorer(net, X_test, y_test)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 219, in __call__\n    return self._score(\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 261, in _score\n    y_pred = method_caller(estimator, \"predict\", X)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 71, in _cached_call\n    return getattr(estimator, method)(*args, **kwargs)\n  File \"/home/chenka@staff.technion.ac.il/anaconda3/envs/VoiceDeep/lib/python3.9/site-packages/skorch/classifier.py\", line 208, in predict\n    return self.predict_proba(X).argmax(axis=1)\nnumpy.AxisError: axis 1 is out of bounds for array of dimension 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y=y.type(torch.LongTensor)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "\n",
    "estimator = NeuralNetClassifier(model,max_epochs=10,lr=0.1,iterator_train__shuffle=True,optimizer=torch.optim.Adam,verbose=True)\n",
    "\n",
    "params = {'optimizer__lr':[1,0.1,0.01]}\n",
    "\n",
    "cv = GridSearchCV(estimator,params,verbose=True)\n",
    "cv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>pid</th>\n",
       "      <th>hostname</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>timesteps_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>warmup_time</th>\n",
       "      <th>config/lr</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.089950</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>daf05_00000</td>\n",
       "      <td>8d24621645384384a6f7a0c4c1c57fa8</td>\n",
       "      <td>2022-05-22_22-46-43</td>\n",
       "      <td>1653248803</td>\n",
       "      <td>19.970182</td>\n",
       "      <td>91291</td>\n",
       "      <td>sipl-gpu40-u.staff.technion.ac.il</td>\n",
       "      <td>132.68.58.49</td>\n",
       "      <td>19.970182</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.100</td>\n",
       "      <td>/home/chenka@staff.technion.ac.il/ray_results/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.094629</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>daf05_00002</td>\n",
       "      <td>639bbd64fd51453cb440eaa06ca0c6e6</td>\n",
       "      <td>2022-05-22_22-47-27</td>\n",
       "      <td>1653248847</td>\n",
       "      <td>19.622019</td>\n",
       "      <td>91896</td>\n",
       "      <td>sipl-gpu40-u.staff.technion.ac.il</td>\n",
       "      <td>132.68.58.49</td>\n",
       "      <td>19.622019</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.001</td>\n",
       "      <td>/home/chenka@staff.technion.ac.il/ray_results/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.110639</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>daf05_00001</td>\n",
       "      <td>336f217ebb0949e38efb97d72ea206e1</td>\n",
       "      <td>2022-05-22_22-47-05</td>\n",
       "      <td>1653248825</td>\n",
       "      <td>19.924161</td>\n",
       "      <td>91592</td>\n",
       "      <td>sipl-gpu40-u.staff.technion.ac.il</td>\n",
       "      <td>132.68.58.49</td>\n",
       "      <td>19.924161</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.010</td>\n",
       "      <td>/home/chenka@staff.technion.ac.il/ray_results/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  ...                                             logdir\n",
       "0  0.645833  ...  /home/chenka@staff.technion.ac.il/ray_results/...\n",
       "1  0.447917  ...  /home/chenka@staff.technion.ac.il/ray_results/...\n",
       "2  0.572917  ...  /home/chenka@staff.technion.ac.il/ray_results/...\n",
       "\n",
       "[3 rows x 20 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.tune import ExperimentAnalysis\n",
    "analysis = ExperimentAnalysis(\"~/ray_results/train_model_2022-05-22_22-56-15\")\n",
    "\n",
    "analysis.dataframe()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d213c2aaf104d79dc69cea7841b9239703446d03b5d9881128cd1fc29cd49aa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('VoiceDeep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
