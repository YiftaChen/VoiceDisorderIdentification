{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "from transformations.transform import WaveformToInput as TorchTransform\n",
    "from architecture.backend.yamnet.params import YAMNetParams\n",
    "from architecture.backend.yamnet.model import yamnet\n",
    "from architecture.backend.yamnet.model import yamnet_category_metadata\n",
    "\n",
    "from architecture.classifier.classification import Classifier\n",
    "\n",
    "from datasets.SvdExDataset import SvdCutOffShort\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Directory should not be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/chenka@staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000001vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000001vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000001vscode-remote?line=4'>5</a>\u001b[0m dataset \u001b[39m=\u001b[39m SvdCutOffShort(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/Users/yiftachedelstain/Development/VoiceDisorderIdentification/data\u001b[39;49m\u001b[39m\"\u001b[39;49m,classification_binary\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000001vscode-remote?line=5'>6</a>\u001b[0m loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000001vscode-remote?line=6'>7</a>\u001b[0m     dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000001vscode-remote?line=7'>8</a>\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000001vscode-remote?line=8'>9</a>\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000001vscode-remote?line=9'>10</a>\u001b[0m     num_workers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000001vscode-remote?line=10'>11</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B132.68.58.49/home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/tools/training_yamnet.ipynb#ch0000001vscode-remote?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_val_test_split\u001b[39m(ds):\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/datasets/SvdExDataset.py:48\u001b[0m, in \u001b[0;36mSvdCutOffShort.__init__\u001b[0;34m(self, root_dir, data_transform, label_transform, class_definitions, classification_binary, overfit_test)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root_dir, data_transform\u001b[39m=\u001b[39mdefault_transforms,label_transform\u001b[39m=\u001b[39mdefault_label_transforms, class_definitions\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,classification_binary\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,overfit_test \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=47'>48</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root_dir,data_transform,label_transform,class_definitions,classification_binary)\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=48'>49</a>\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=49'>50</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles \u001b[39m=\u001b[39m [file \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles \u001b[39mif\u001b[39;00m librosa\u001b[39m.\u001b[39mget_duration(filename\u001b[39m=\u001b[39mfile)\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mcfg\u001b[39m.\u001b[39mVOICE_SAMPLE_MIN_LENGTH]\n",
      "File \u001b[0;32m~/VoiceDisorderIdentification/src/datasets/SvdExDataset.py:26\u001b[0m, in \u001b[0;36mSvdExtendedVoiceDataset.__init__\u001b[0;34m(self, root_dir, data_transform, label_transform, class_definitions, classification_binary)\u001b[0m\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=23'>24</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root,f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m files \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m f\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m  f\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m     <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=24'>25</a>\u001b[0m     \u001b[39m# assert len(files) == 0 or (len(files) != 0 and \u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/chenka%40staff.technion.ac.il/VoiceDisorderIdentification/src/datasets/SvdExDataset.py?line=25'>26</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mDirectory should not be empty\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Directory should not be empty"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "dataset = SvdCutOffShort(r\"/Users/yiftachedelstain/Development/VoiceDisorderIdentification/data\",classification_binary=True)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "def train_val_test_split(ds):\n",
    "        ds_len =  len(ds)\n",
    "        len_test = math.floor(ds_len*0.2)\n",
    "        len_train_vald = ds_len - len_test\n",
    "        len_train = math.ceil(len_train_vald*0.8)\n",
    "        len_vald = len_train_vald - len_train\n",
    "        return torch.utils.data.random_split(ds, [len_train,len_vald,len_test]) \n",
    "\n",
    "train,val,test = train_val_test_split(dataset)\n",
    "# print(len(train),len(val),len(test),len(dataset))\n",
    "pt_model = Classifier([512,64])\n",
    "# print(pt_model)\n",
    "pt_model.eval()\n",
    "print(len(dataset))\n",
    "with torch.no_grad():\n",
    "\n",
    "# print(pt_model)\n",
    "    for epoch in range(2):\n",
    "        with tqdm(loader) as t:\n",
    "            for idx,x in enumerate(t):\n",
    "                # x = torch.from_numpy(patches)\n",
    "                # x = x.unsqueeze(1)  # [5, 96, 64] -> [5, 1, 96, 64]\n",
    "                t.set_description(f\"epoch {epoch}: train loss is {idx}\")\n",
    "                pt_pred = pt_model(x['data'])\n",
    "                # print(pt_pred['classification'])\n",
    "                # print(x['classification'])\n",
    "                # assert(x['classification'].all())\n",
    "                # print(pt_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainer.train_svd \n",
    "import torch.nn as nn\n",
    "import torch.optim \n",
    "dataset = SvdCutOffShort(r\"/home/yiftach.ede@staff.technion.ac.il/Desktop/SVD\",classification_binary=True,overfit_test = False)\n",
    "model = Classifier([512,128])\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "hyper_params = {\n",
    "    'train_batch_size':128,\n",
    "    'vald_batch_size':128,\n",
    "    'test_batch_size':128,\n",
    "    'num_workers':5,\n",
    "    'epochs':100\n",
    "}\n",
    "trainer = trainer.train_svd.Trainer(dataset=dataset,model=model,optimizers=opt,critereon=loss,hyper_params=hyper_params)\n",
    "model = trainer.train()\n",
    "trainer.test(model[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d213c2aaf104d79dc69cea7841b9239703446d03b5d9881128cd1fc29cd49aa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('VoiceDeep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
